{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5a1f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import ntpath\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9389cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'FD-027': '/home/miguel/GI/1.5 - Synthetic Data Generation/diffuse-gen/diffuse-gen/image_samples_FD-027/diffgen-2025-07-13-00-54/styled_samples_400x256x256x4.pkl',\n",
    "    'FD-029': '/home/miguel/GI/1.5 - Synthetic Data Generation/diffuse-gen/diffuse-gen/image_samples_FD-029/diffgen-2025-07-13-07-47/styled_samples_560x256x256x4.pkl',\n",
    "    'FD-030': '',\n",
    "    'FD-031': '/home/miguel/GI/1.5 - Synthetic Data Generation/diffuse-gen/diffuse-gen/image_samples_FD-031/diffgen-2025-07-13-17-25/styled_samples_860x256x256x4.pkl',\n",
    "    'FD-032': ''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6baa0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def is_cohesive_mask(mask_gray: np.ndarray,\n",
    "                     thresh_method: str = 'otsu',\n",
    "                     min_area: int = 50,\n",
    "                     main_frac_thresh: float = 0.6,\n",
    "                     max_extra_components: int = 1) -> bool:\n",
    "    \"\"\"\n",
    "    Decide whether a grayscale mask is coherent (one big region) or incohesive\n",
    "    (many small regions).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask_gray : np.ndarray\n",
    "        2D array, single-channel mask (uint8 or float in [0,1]).\n",
    "    thresh_method : str\n",
    "        'otsu' | 'adaptive' | 'fixed' — how to binarize.\n",
    "    min_area : int\n",
    "        Ignore components smaller than this (noise filter).\n",
    "    main_frac_thresh : float\n",
    "        Fraction of total mask area the largest component must exceed to be\n",
    "        considered dominant.\n",
    "    max_extra_components : int\n",
    "        Allow at most this many additional (filtered) components.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if “coherent” (one dominant region), False otherwise.\n",
    "    \"\"\"\n",
    "    # ——— ensure uint8 [0,255] ———\n",
    "    if mask_gray.dtype == np.float32 or mask_gray.dtype == np.float64:\n",
    "        img = (mask_gray * 255).astype(np.uint8)\n",
    "    else:\n",
    "        img = mask_gray.astype(np.uint8)\n",
    "\n",
    "    # ——— binarize ———\n",
    "    if thresh_method == 'otsu':\n",
    "        _, bw = cv2.threshold(img, 0, 255,\n",
    "                              cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    elif thresh_method == 'adaptive':\n",
    "        bw = cv2.adaptiveThreshold(img, 255,\n",
    "                                   cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY,\n",
    "                                   blockSize=11, C=2)\n",
    "    else:  # 'fixed'\n",
    "        _, bw = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # ——— connected components ———\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(bw,\n",
    "                                                                  connectivity=8)\n",
    "    # stats[:, cv2.CC_STAT_AREA] is pixel-area for each label;\n",
    "    # skip label 0 (background)\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "\n",
    "    # ——— filter out tiny noise blobs ———\n",
    "    areas = areas[areas >= min_area]\n",
    "    if areas.size == 0:\n",
    "        return False\n",
    "\n",
    "    total = areas.sum()\n",
    "    largest = areas.max()\n",
    "    extras = areas.size - 1\n",
    "\n",
    "    # ——— decision ———\n",
    "    # coherent if one blob covers ≥ main_frac_thresh of all mask pixels,\n",
    "    # and there are at most max_extra_components others\n",
    "    if (largest / total) >= main_frac_thresh and extras <= max_extra_components:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f9c051bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_folder_path = '/home/miguel/GI/1.5 - Synthetic Data Generation/Singan-Seg/unet_singan_augmented_datasets_2/augmented_dataset_expansion_factor_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7530abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = '../augmented_datasets_varied_expansion_factor'\n",
    "shutil.rmtree(dataset_folder, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6cc0bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(dataset_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f20fc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmentation_amount {'FD-027': 50, 'FD-029': 465, 'FD-031': 303}\n",
      "augmentation_amount {'FD-027': 50, 'FD-029': 465, 'FD-031': 303}\n",
      "augmentation_amount {'FD-027': 50, 'FD-029': 465, 'FD-031': 303}\n",
      "augmentation_amount {'FD-027': 50, 'FD-029': 465, 'FD-031': 303}\n"
     ]
    }
   ],
   "source": [
    "for expansion_factor in [\n",
    "    0.5, 0.75, 1.0, 1.4\n",
    "]:\n",
    "    expansion_factor_folder = os.path.join(dataset_folder, f'expansion_factor_{expansion_factor}')\n",
    "    augmentation_amount = {}\n",
    "    for subject in list(paths.keys()):\n",
    "        path = paths[subject]\n",
    "        if path:\n",
    "            cv_subject_folder = os.path.join(expansion_factor_folder, subject)\n",
    "            train_folder = os.path.join(cv_subject_folder, 'train')\n",
    "            os.makedirs(train_folder, exist_ok=True)\n",
    "            val_folder = os.path.join(cv_subject_folder, 'val')\n",
    "            os.makedirs(val_folder, exist_ok=True)\n",
    "            \n",
    "            # Copy over all the images for the CV-subject, originally. \n",
    "            original_cv_subject_folder = os.path.join(original_dataset_folder_path, subject)\n",
    "            original_train_folder = os.path.join(original_cv_subject_folder, 'train')\n",
    "            original_val_folder = os.path.join(original_cv_subject_folder, 'val')\n",
    "\n",
    "            # Copy all the original images to the new folder\n",
    "            for original_img_path in os.listdir(original_train_folder):\n",
    "                original_img_full_path = os.path.join(original_train_folder, original_img_path)\n",
    "                if original_img_path.endswith('.png'):\n",
    "                    shutil.copy(original_img_full_path, train_folder)\n",
    "            \n",
    "            for original_img_path in os.listdir(original_val_folder):\n",
    "                original_img_full_path = os.path.join(original_val_folder, original_img_path)\n",
    "                if original_img_path.endswith('.png'):\n",
    "                    shutil.copy(original_img_full_path, val_folder)\n",
    "\n",
    "            # Load the augmented data\n",
    "            num_augmented_images = 0\n",
    "            subject_image_data = pickle.load(open(path, 'rb'))\n",
    "            for original_img_path in subject_image_data.keys():\n",
    "                subject_img_data_list = subject_image_data[original_img_path]\n",
    "                for img in subject_img_data_list:\n",
    "                    original_img_name = os.path.basename(original_img_path)\n",
    "                    \n",
    "                    synthetic_image_path = os.path.join(train_folder, f\"{original_img_name.replace('-image.png', '-synthetic-image.png')}\")\n",
    "                    synthetic_mask_path = os.path.join(train_folder, f\"{original_img_name.replace('-image.png', '-synthetic-mask.png')}\")\n",
    "                    # Ensure the augmented data is of a high quality. \n",
    "                    synthetic_mask = img[:, :, 3]\n",
    "                    synthetic_image = img[:, :, :3]\n",
    "                    if (is_cohesive_mask(synthetic_mask)):\n",
    "                        # Export the mask to the location\n",
    "                        cv2.imwrite(synthetic_mask_path, synthetic_mask)\n",
    "\n",
    "                        # Export the image to the location\n",
    "                        cv2.imwrite(synthetic_image_path, synthetic_image)\n",
    "\n",
    "                        num_augmented_images += 1\n",
    "            augmentation_amount[subject] = num_augmented_images\n",
    "    print('augmentation_amount', augmentation_amount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7936ffe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7bb53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e6f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87a986ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_mask = img[:, :, 3]\n",
    "synthetic_image = img[:, :, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "256a9bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_cohesive_mask(synthetic_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "caa2a927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FD-032-slice-53-image.png'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(original_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decacfbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68105996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864085c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Recreate the original training dataset\n",
    "\n",
    "# 2. Load the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3fc284a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mlen\u001b[39m([arr \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m subject_image_data[\u001b[43mkey\u001b[49m] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m subject_image_data.keys()])\n",
      "\u001b[31mNameError\u001b[39m: name 'key' is not defined"
     ]
    }
   ],
   "source": [
    "len([(arr for arr in subject_image_data[key]) for key in subject_image_data.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f53fce35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<generator object <genexpr> at 0x78f6c0b96b00>,\n",
       " <generator object <genexpr> at 0x78f6c0b96800>,\n",
       " <generator object <genexpr> at 0x78f6c0b96980>,\n",
       " <generator object <genexpr> at 0x78f6c0b96d40>,\n",
       " <generator object <genexpr> at 0x78f6c0b96ec0>,\n",
       " <generator object <genexpr> at 0x78f6c0b96e00>,\n",
       " <generator object <genexpr> at 0x78f6c0b97100>,\n",
       " <generator object <genexpr> at 0x78f6c0b96f80>,\n",
       " <generator object <genexpr> at 0x78f6c0b971c0>,\n",
       " <generator object <genexpr> at 0x78f6c0b97040>,\n",
       " <generator object <genexpr> at 0x78f6c0b97280>,\n",
       " <generator object <genexpr> at 0x78f6c0b97340>,\n",
       " <generator object <genexpr> at 0x78f6c0b97400>,\n",
       " <generator object <genexpr> at 0x78f6c0b974c0>,\n",
       " <generator object <genexpr> at 0x78f6c0b97700>,\n",
       " <generator object <genexpr> at 0x78f6c0b97580>,\n",
       " <generator object <genexpr> at 0x78f6c0b97640>,\n",
       " <generator object <genexpr> at 0x78f6c0b97940>,\n",
       " <generator object <genexpr> at 0x78f6c0b97a00>,\n",
       " <generator object <genexpr> at 0x78f6c0b97ac0>,\n",
       " <generator object <genexpr> at 0x78f6c0b97b80>,\n",
       " <generator object <genexpr> at 0x78f6c0b97c40>,\n",
       " <generator object <genexpr> at 0x78f6c0b977c0>,\n",
       " <generator object <genexpr> at 0x78f6c0b97d00>,\n",
       " <generator object <genexpr> at 0x78f6c0b97dc0>,\n",
       " <generator object <genexpr> at 0x78f6c0b97880>,\n",
       " <generator object <genexpr> at 0x78f6c0b97e80>,\n",
       " <generator object <genexpr> at 0x78f6c0b97f40>,\n",
       " <generator object <genexpr> at 0x78f692d10040>,\n",
       " <generator object <genexpr> at 0x78f692d10100>,\n",
       " <generator object <genexpr> at 0x78f692d101c0>,\n",
       " <generator object <genexpr> at 0x78f692d10280>,\n",
       " <generator object <genexpr> at 0x78f692d10340>,\n",
       " <generator object <genexpr> at 0x78f692d10400>,\n",
       " <generator object <genexpr> at 0x78f692d104c0>,\n",
       " <generator object <genexpr> at 0x78f692d10580>,\n",
       " <generator object <genexpr> at 0x78f692d10640>,\n",
       " <generator object <genexpr> at 0x78f692d10700>,\n",
       " <generator object <genexpr> at 0x78f692d107c0>,\n",
       " <generator object <genexpr> at 0x78f692d10880>,\n",
       " <generator object <genexpr> at 0x78f692d10940>,\n",
       " <generator object <genexpr> at 0x78f692d10a00>,\n",
       " <generator object <genexpr> at 0x78f692d10ac0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(arr for arr in subject_image_data[key]) for key in subject_image_data.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99099c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc-2025-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
